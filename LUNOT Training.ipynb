{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sxLklutV7Y2u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from utils.simulators import Steel_APT_Dataset\n",
        "\n",
        "device = torch.device('cpu')\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_inputs(data: pd.DataFrame, k: int = 10) -> np.ndarray:\n",
        "    knn = NearestNeighbors(n_neighbors=k + 1)\n",
        "    knn.fit(data[[\"X\", \"Y\", \"Z\"]])\n",
        "    distances, indexes = knn.kneighbors(data[[\"X\", \"Y\", \"Z\"]])\n",
        "    return distances[:, 1:]  # 1st nieghbour is the point itself\n",
        "\n",
        "class Training_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, preprocessed_inputs: np.ndarray, cluster_labels: np.ndarray):\n",
        "        self.X = preprocessed_inputs\n",
        "        self.Y = cluster_labels\n",
        "        self.n_examples = self.Y.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.Y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_examples\n",
        "\n",
        "def get_auprc(model: torch.nn.Sequential, X: torch.Tensor, Y: torch.Tensor) -> float:\n",
        "    Y_pred = model(X).detach().cpu().numpy()\n",
        "    Y = Y.cpu().numpy()\n",
        "    precision, recall, _ = precision_recall_curve(Y, Y_pred)\n",
        "    return auc(x=recall, y=precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0Grtrkpj8Gku"
      },
      "outputs": [],
      "source": [
        "class LUNOT(nn.Module):\n",
        "    def __init__(self, k: int, layer_size: int = 128, layer_count: int = 8, dropout: float = 0.0):\n",
        "        super(LUNOT, self).__init__()\n",
        "\n",
        "        layers = [nn.Linear(k, layer_size), nn.Dropout(dropout), nn.GELU()]\n",
        "        for i in range(layer_count - 2):\n",
        "            layers += [nn.Linear(layer_size, layer_size), nn.Dropout(dropout), nn.GELU()]\n",
        "            if i % 2 == 0:\n",
        "                layers += [nn.BatchNorm1d(layer_size, affine=False)]\n",
        "        layers += [nn.Linear(layer_size, 1), nn.Sigmoid()]\n",
        "        \n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.network(x)\n",
        "        return torch.squeeze(out, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = Steel_APT_Dataset(\n",
        "    unit_cells_per_side=150,\n",
        "    cluster_relative_density=200,\n",
        "    cluster_atom_counts=np.random.randint(low=10, high=50, size=400),\n",
        ")\n",
        "train_data = train_dataset.data[train_dataset.data['Element']!='Fe']\n",
        "\n",
        "val_dataset = Steel_APT_Dataset(\n",
        "    unit_cells_per_side=100,\n",
        "    cluster_relative_density=200,\n",
        "    cluster_atom_counts=np.random.randint(low=10, high=50, size=120),\n",
        ")\n",
        "val_data = val_dataset.data[val_dataset.data['Element']!='Fe']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "is cluster\n",
              "0    68079\n",
              "1     6590\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data['is cluster'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "is cluster\n",
              "0    20053\n",
              "1     1949\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data['is cluster'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model(train_data: pd.DataFrame, val_data: pd.DataFrame, lr=0.001, n_neighbours=10, layer_size=32, batch_size=64, layer_count=3, lr_schedule_k=1.0) -> nn.Module:\n",
        "    X_val = preprocess_inputs(val_data, k=n_neighbours)\n",
        "    Y_val = val_data['is cluster'].to_numpy()\n",
        "    X_train = preprocess_inputs(train_data, k=n_neighbours)\n",
        "    Y_train = train_data['is cluster'].to_numpy()\n",
        "    \n",
        "    X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
        "    Y_val = torch.tensor(Y_val, dtype=torch.float32).to(device)\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "    Y_train = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
        "\n",
        "    training_dataset = Training_Dataset(X_train, Y_train)\n",
        "    train_data_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = LUNOT(k=n_neighbours, layer_size=layer_size, layer_count=layer_count).to(device, dtype=torch.float32)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: lr_schedule_k**epoch)\n",
        "\n",
        "    losses, train_scores, val_scores = [], [], []\n",
        "\n",
        "    for epoch in range(1, 21):\n",
        "\n",
        "        model.train()\n",
        "        for X, Y in train_data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            Y_pred = model(X)\n",
        "            loss = criterion(Y_pred, Y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        losses.append(loss.item())\n",
        "        scheduler.step()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            train_scores.append(get_auprc(model, X_train, Y_train))\n",
        "            val_scores.append(get_auprc(model, X_val, Y_val))\n",
        "\n",
        "        if epoch >= 3 and np.std(val_scores[-3:]) < 0.01:\n",
        "            # print(f'stopping at epoch {epoch} due to low variance in validation scores')\n",
        "            break\n",
        "\n",
        "    print(f'losses: {losses}')\n",
        "    print(f'train_scores: {train_scores}')\n",
        "    print(f'val_scores: {val_scores}')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "losses: [0.2537890672683716, 0.13283410668373108, 0.0869079977273941]\n",
            "train_scores: [0.7381278863311806, 0.740625348432118, 0.7418195275067734]\n",
            "val_scores: [0.7567422019333573, 0.7623879586608083, 0.7649024199899588]\n"
          ]
        }
      ],
      "source": [
        "model = get_model(train_data, val_data, lr=0.02, n_neighbours=50, layer_size=150, batch_size=300,\n",
        "                   layer_count=4, lr_schedule_k=0.2) #values from hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scripted_model = torch.jit.script(model)\n",
        "scripted_model.save('utils/LUNOT_finetuned')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
